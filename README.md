# ğŸ’¼ | Modelo de propensiÃ³n a la aceptaciÃ³n de opciones de pago

Este proyecto desarrolla una soluciÃ³n analÃ­tica E2E que permite pronosticar si un cliente en mora aceptarÃ¡ alguna de las opciones de pago preaprobadas ofrecidas por Bancolombia, dentro de una ventana de un mes.

El modelo propuesto busca ser integrado como una nueva variable estratÃ©gica dentro del sistema de priorizaciÃ³n de cartera, aumentando la eficiencia de la gestiÃ³n y ayudando a disminuir la cartera vencida.

---

## ğŸ¦ | Contexto del negocio

Bancolombia ofrece diversas **opciones de pago** como alivio financiero para clientes en mora (e.g., ampliaciÃ³n de plazo, reducciÃ³n de cuota, renegociaciÃ³n de tasa). Estas se manejan como productos preaprobados, pero su aceptaciÃ³n depende de mÃºltiples factores del cliente y la obligaciÃ³n.

La predicciÃ³n de esta aceptaciÃ³n con antelaciÃ³n permite una gestiÃ³n mÃ¡s proactiva, focalizada y eficiente.

---

## ğŸ¯ | Objetivo del proyecto

DiseÃ±ar, entrenar y desplegar un modelo de clasificaciÃ³n binaria que determine si una obligaciÃ³n en mora aceptarÃ¡ una opciÃ³n de pago en el siguiente mes de gestiÃ³n.

**Variable objetivo (ğ‘Œ):**

> - `1`: El cliente aceptÃ³ una opciÃ³n de pago.
> - `0`: El cliente no aceptÃ³ una opciÃ³n de pago.

---

## ğŸ—‚ï¸ | Estructura del proyecto

```plaintext
modelo_operaciones_pago/
â”‚
â”œâ”€â”€ README.md                <- Documento actual
â”‚
â”œâ”€â”€ datos/
â”‚   â”œâ”€â”€ raw/                <- Archivos originales entregados en la prueba
â”‚   â”œâ”€â”€ interim/            <- Datos listos para modelado y predicciÃ³n 
â”‚   â””â”€â”€ processed/          <- Datos limpios y unificados
â”‚
â”œâ”€â”€ modelos/                 <- Modelos entrenados y serializados (.pkl)
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_pre_procesamiento_datos.ipynb
â”‚   â”œâ”€â”€ 02_procesamiento_datos.ipynb
â”‚   â”œâ”€â”€ 03_entrenamiento_modelo.ipynb
â”‚   â””â”€â”€ 04_generacion_predicciones.ipynb
â”‚
â”œâ”€â”€ referencias/             <- Diccionarios de datos y documentaciÃ³n externa
â”‚
â”œâ”€â”€ requerimientos.txt       <- Dependencias para reproducir el entorno
â””â”€â”€ pyproject.toml           <- ConfiguraciÃ³n del proyecto
```

---

## ğŸ” Flujo de Trabajo

### ğŸ§¼ 1. Pre-procesamiento de datos

- Carga y exploraciÃ³n inicial de todos los archivos `.csv`.
- ValidaciÃ³n de fechas de corte (solo 202308 a 202312).
- UniÃ³n de fuentes para crear una **sÃ¡bana consolidada**.
- IdentificaciÃ³n y tratamiento de **valores atÃ­picos** y **valores nulos**.
- ExportaciÃ³n de la sÃ¡bana limpia (`processed/`).

### âš™ï¸ 2. Procesamiento de variables

- AnÃ¡lisis de distribuciÃ³n y utilidad de cada variable.
- EliminaciÃ³n de columnas redundantes o poco informativas.
- ConversiÃ³n de variables categÃ³ricas con `get_dummies`.
- Escalado de variables numÃ©ricas.
- ExportaciÃ³n final de datos procesados (`procesados/`).

### ğŸ§  3. Entrenamiento del modelo

- SeparaciÃ³n en `X` y `y`.
- SelecciÃ³n de variables con `SelectKBest`.
- ComparaciÃ³n de modelos: RegresiÃ³n LogÃ­stica, Random Forest, XGBoost.
- ValidaciÃ³n cruzada, mÃ©tricas de rendimiento, y evaluaciÃ³n con:
  - Matriz de confusiÃ³n
  - Curva ROC
  - AnÃ¡lisis por deciles
- Modelo final seleccionado: **RegresiÃ³n LogÃ­stica** por buen desempeÃ±o y simplicidad.
- SerializaciÃ³n del modelo y features seleccionadas (`modelos/`).

### ğŸ“¤ 4. GeneraciÃ³n de predicciones

- ImportaciÃ³n de modelo y columnas relevantes.
- AplicaciÃ³n sobre nuevos datos (`oot`).
- GeneraciÃ³n del archivo `resultado_prueba.csv` en el formato exigido:
  
```csv
id,var_rpta_alt
123456#987#0001,1
123456#987#0002,0
```

---

## ğŸ“ˆ | Resultados del modelo

- **Modelo seleccionado**: RegresiÃ³n LogÃ­stica
- **MÃ©trica principal**: F1 Score
- **EvaluaciÃ³n final**: [incluir valor obtenido, por ejemplo: `F1 Score = 0.76`]
- Se logrÃ³ un buen balance entre precisiÃ³n y sensibilidad, con interpretabilidad alta.

---

## ğŸ› ï¸ | Requisitos del entorno

Crear un entorno virtual y ejecutar:

```bash
pip install -r requirements.txt
```

Versiones clave:

- Python 3.10+
- pandas, numpy, scikit-learn, xgboost, seaborn, matplotlib, etc.

---

## ğŸ’¡ |Â Consideraciones finales y futuras mejoras

- Despliegue propuesto mediante una API REST con FastAPI o Flask.
- AutomatizaciÃ³n y monitoreo del modelo en producciÃ³n.
- Posibilidad de actualizar el modelo mensualmente con nuevas cohortes.

---

## ğŸ’¡ Autor y agradecimientos

[Laura SÃ¡nchez Giraldo](mailto:laurasanchezgiraldo@outlook.es)  

Este proyecto fue desarrollado como parte de una prueba tÃ©cnica para **Bancolombia**, destacando una soluciÃ³n sÃ³lida, transparente y modular.  

> Con ayuda de GitHub Copilot, ChatGPT, Claude y Gemini, como copilotos tÃ©cnicos en todo el camino ğŸš€
